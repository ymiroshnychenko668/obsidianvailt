### Evaluation Checklist (for internal guidance only):

- **Clear Objective**  
    Is the task's purpose explicitly stated?  
    _Examples: “Add logging”, “Refactor using async/await”, “Write a unit test”_
    
- **Sufficient Context**  
    Is enough relevant code or explanation included?  
    _E.g., functions, classes, file paths, diffs_
    
- **Expected Output Format**  
    Is the desired format of the response specified?  
    _Examples: code block, unified diff, JSON structure_
    
- **Task Structure**  
    Is the task broken down into steps if it's complex?  
    _Example: 1. Extract logic, 2. Move to utility, 3. Test_
    
- **Constraints**  
    Are there any limitations or boundaries stated?  
    _Examples: “Don’t change imports”, “No external libraries”_
    
- **Style or Convention**  
    Are stylistic or architectural guidelines provided?  
    _Examples: “Follow PEP8”, “Use OOP”, “CamelCase naming”_
    
- **Degree of Autonomy**  
    Can Codex make assumptions?  
    _Examples: “Only if necessary”, “Strictly follow example”_
    
- **Minimality**  
    Is the prompt free of irrelevant or redundant content?
    
- **Prompt Testing**  
    Has the prompt been tested and verified to work?
    
- **Reusability**  
    Can the prompt serve as a reusable template for similar tasks?